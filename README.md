# Neural Networks & Deep Learning Tasks (MNIST)

This repository contains a set of experiments and analysis tasks designed to understand
the fundamentals of neural networks, training behavior, optimization, and regularization
using the MNIST handwritten digits dataset.

## Project Overview
The project focuses on building a simple neural network model and analyzing:
- Prediction behavior
- Training dynamics
- Regularization techniques
- Optimizers
- Activation functions
- Model capacity

All experiments are implemented in a single Jupyter Notebook, while explanations and
analysis are documented separately.

## Tasks Included
- Task 01: Prediction Analysis
- Task 02: Custom Image Generalization
- Task 03: Epoch-Based Learning Curves
- Task 04: EarlyStopping Behavior
- Task 05: Dropout Ablation Study
- Task 06: L2 Regularization
- Task 07: Optimizer Comparison
- Task 08: Batch Size and Gradient Noise
- Task 09: Activation Function Variants
- Task 10: Weight Inspection and Model Capacity

## Repository Structure
## Notes
- All experiments were implemented using TensorFlow and Keras.
- The goal of this project is understanding concepts, not maximizing accuracy.
- Simple language is used to clearly explain neural network behavior.
